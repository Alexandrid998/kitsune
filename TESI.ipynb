{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Danmini=pd.read_csv('benign_traffic_Danmini_Doorbell.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Danmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Danmini['Benign']=1\n",
    "benign_traffic_Danmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Webcam=pd.read_csv('benign_traffic_Webcam.csv', delimiter=',')\n",
    "benign_traffic_Webcam['Benign']=1\n",
    "benign_traffic_Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Ecobee_Thermostat=pd.read_csv('benign_traffic_Ecobee_Thermostat.csv', delimiter=',')\n",
    "benign_traffic_Ecobee_Thermostat['Benign']=1\n",
    "benign_traffic_Ecobee_Thermostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Ennio_Doorbell=pd.read_csv('benign_traffic_Ennio_Doorbell.csv', delimiter=',')\n",
    "benign_traffic_Ennio_Doorbell['Benign']=1\n",
    "benign_traffic_Ennio_Doorbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Baby_Monitor=pd.read_csv('benign_traffic_Baby_Monitor.csv', delimiter=',')\n",
    "benign_traffic_Baby_Monitor['Benign']=1\n",
    "benign_traffic_Baby_Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_838_Security_Camera=pd.read_csv('benign_traffic_838_Security_Camera.csv', delimiter=',')\n",
    "benign_traffic_838_Security_Camera['Benign']=1\n",
    "benign_traffic_838_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_Danmini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_737E_Security_Camera=pd.read_csv('benign_traffic_737E_Security_Camera.csv', delimiter=',')\n",
    "benign_traffic_737E_Security_Camera['Benign']=1\n",
    "benign_traffic_737E_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_1002_WHT_Security_Camera=pd.read_csv('benign_traffic_1002_WHT_Security_Camera.csv', delimiter=',')\n",
    "benign_traffic_1002_WHT_Security_Camera['Benign']=1\n",
    "benign_traffic_1002_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_1003_WHT_Security_Camera=pd.read_csv('benign_traffic_1003_WHT_Security_Camera.csv', delimiter=',')\n",
    "benign_traffic_1003_WHT_Security_Camera['Benign']=1\n",
    "benign_traffic_1003_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic= pd.concat([benign_traffic_1002_WHT_Security_Camera,benign_traffic_1003_WHT_Security_Camera,benign_traffic_737E_Security_Camera,benign_traffic_838_Security_Camera,benign_traffic_Baby_Monitor,benign_traffic_Danmini,benign_traffic_Ecobee_Thermostat,benign_traffic_Webcam,benign_traffic_Ennio_Doorbell], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1002_WHT_Security_Camera_combo=pd.read_csv('gafgyt_attacks_1002_WHT_Security_Camera/combo.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1002_WHT_Security_Camera_junk=pd.read_csv('gafgyt_attacks_1002_WHT_Security_Camera/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_1002_WHT_Security_Camera_scan=pd.read_csv('gafgyt_attacks_1002_WHT_Security_Camera/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_1002_WHT_Security_Camera_tcp=pd.read_csv('gafgyt_attacks_1002_WHT_Security_Camera/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_1002_WHT_Security_Camera_udp=pd.read_csv('gafgyt_attacks_1002_WHT_Security_Camera/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1002_WHT_Security_Camera=pd.concat([gafgyt_attacks_1002_WHT_Security_Camera_combo,gafgyt_attacks_1002_WHT_Security_Camera_junk,gafgyt_attacks_1002_WHT_Security_Camera_scan,gafgyt_attacks_1002_WHT_Security_Camera_tcp,gafgyt_attacks_1002_WHT_Security_Camera_udp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1002_WHT_Security_Camera.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1002_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1003_WHT_Security_Camera_combo=pd.read_csv('gafgyt_attacks_1003_WHT_Security_Camera/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_1003_WHT_Security_Camera_junk=pd.read_csv('gafgyt_attacks_1003_WHT_Security_Camera/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_1003_WHT_Security_Camera_scan=pd.read_csv('gafgyt_attacks_1003_WHT_Security_Camera/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_1003_WHT_Security_Camera_tcp=pd.read_csv('gafgyt_attacks_1003_WHT_Security_Camera/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_1003_WHT_Security_Camera_udp=pd.read_csv('gafgyt_attacks_1003_WHT_Security_Camera/udp.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_1003_WHT_Security_Camera=pd.concat([gafgyt_attacks_1003_WHT_Security_Camera_combo,gafgyt_attacks_1003_WHT_Security_Camera_junk,gafgyt_attacks_1003_WHT_Security_Camera_scan,gafgyt_attacks_1003_WHT_Security_Camera_tcp,gafgyt_attacks_1003_WHT_Security_Camera_udp], ignore_index=True)\n",
    "gafgyt_attacks_1003_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_737E_Security_Camera_combo=pd.read_csv('gafgyt_attacks_737E_Security_Camera/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_737E_Security_Camera_junk=pd.read_csv('gafgyt_attacks_737E_Security_Camera/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_737E_Security_Camera_scan=pd.read_csv('gafgyt_attacks_737E_Security_Camera/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_737E_Security_Camera_tcp=pd.read_csv('gafgyt_attacks_737E_Security_Camera/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_737E_Security_Camera_udp=pd.read_csv('gafgyt_attacks_737E_Security_Camera/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_737E_Security_Camera=pd.concat([gafgyt_attacks_737E_Security_Camera_combo,gafgyt_attacks_737E_Security_Camera_junk,gafgyt_attacks_737E_Security_Camera_scan,gafgyt_attacks_737E_Security_Camera_tcp,gafgyt_attacks_737E_Security_Camera_udp], ignore_index=True)\n",
    "gafgyt_attacks_737E_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_838_Security_Camera_combo=pd.read_csv('gafgyt_attacks_838_Security_Camera/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_838_Security_Camera_junk=pd.read_csv('gafgyt_attacks_838_Security_Camera/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_838_Security_Camera_scan=pd.read_csv('gafgyt_attacks_838_Security_Camera/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_838_Security_Camera_tcp=pd.read_csv('gafgyt_attacks_838_Security_Camera/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_838_Security_Camera_udp=pd.read_csv('gafgyt_attacks_838_Security_Camera/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_838_Security_Camera=pd.concat([gafgyt_attacks_838_Security_Camera_combo,gafgyt_attacks_838_Security_Camera_junk,gafgyt_attacks_838_Security_Camera_scan,gafgyt_attacks_838_Security_Camera_tcp,gafgyt_attacks_838_Security_Camera_udp],ignore_index=True)\n",
    "gafgyt_attacks_838_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Baby_Monitor_combo=pd.read_csv('gafgyt_attacks_Baby_Monitor/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_Baby_Monitor_junk=pd.read_csv('gafgyt_attacks_Baby_Monitor/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_Baby_Monitor_scan=pd.read_csv('gafgyt_attacks_Baby_Monitor/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_Baby_Monitor_tcp=pd.read_csv('gafgyt_attacks_Baby_Monitor/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_Baby_Monitor_udp=pd.read_csv('gafgyt_attacks_Baby_Monitor/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Baby_Monitor=pd.concat([gafgyt_attacks_Baby_Monitor_combo,gafgyt_attacks_Baby_Monitor_junk,gafgyt_attacks_Baby_Monitor_scan,gafgyt_attacks_Baby_Monitor_tcp,gafgyt_attacks_Baby_Monitor_udp],ignore_index=True)\n",
    "gafgyt_attacks_Baby_Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Danmini_Doorbell_combo=pd.read_csv('gafgyt_attacks_Danmini_Doorbell/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_Danmini_Doorbell_junk=pd.read_csv('gafgyt_attacks_Danmini_Doorbell/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_Danmini_Doorbell_scan=pd.read_csv('gafgyt_attacks_Danmini_Doorbell/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_Danmini_Doorbell_tcp=pd.read_csv('gafgyt_attacks_Danmini_Doorbell/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_Danmini_Doorbell_udp=pd.read_csv('gafgyt_attacks_Danmini_Doorbell/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Danmini_Doorbell=pd.concat([gafgyt_attacks_Danmini_Doorbell_combo,gafgyt_attacks_Danmini_Doorbell_junk,gafgyt_attacks_Danmini_Doorbell_scan,gafgyt_attacks_Danmini_Doorbell_tcp,gafgyt_attacks_Danmini_Doorbell_udp],ignore_index=True)\n",
    "gafgyt_attacks_Danmini_Doorbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Ecobee_Thermostat_combo=pd.read_csv('gafgyt_attacks_Ecobee_Thermostat/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_Ecobee_Thermostat_junk=pd.read_csv('gafgyt_attacks_Ecobee_Thermostat/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_Ecobee_Thermostat_scan=pd.read_csv('gafgyt_attacks_Ecobee_Thermostat/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_Ecobee_Thermostat_tcp=pd.read_csv('gafgyt_attacks_Ecobee_Thermostat/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_Ecobee_Thermostat_udp=pd.read_csv('gafgyt_attacks_Ecobee_Thermostat/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Ecobee_Thermostat=pd.concat([gafgyt_attacks_Ecobee_Thermostat_combo,gafgyt_attacks_Ecobee_Thermostat_junk,gafgyt_attacks_Ecobee_Thermostat_scan,gafgyt_attacks_Ecobee_Thermostat_tcp,gafgyt_attacks_Ecobee_Thermostat_udp],ignore_index=True)\n",
    "gafgyt_attacks_Ecobee_Thermostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Ennio_Doorbell_combo=pd.read_csv('gafgyt_attacks_Ennio_Doorbell/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_Ennio_Doorbell_junk=pd.read_csv('gafgyt_attacks_Ennio_Doorbell/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_Ennio_Doorbell_scan=pd.read_csv('gafgyt_attacks_Ennio_Doorbell/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_Ennio_Doorbell_tcp=pd.read_csv('gafgyt_attacks_Ennio_Doorbell/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_Ennio_Doorbell_udp=pd.read_csv('gafgyt_attacks_Ennio_Doorbell/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Ennio_Doorbell=pd.concat([gafgyt_attacks_Ennio_Doorbell_combo,gafgyt_attacks_Ennio_Doorbell_junk,gafgyt_attacks_Ennio_Doorbell_scan,gafgyt_attacks_Ennio_Doorbell_tcp,gafgyt_attacks_Ennio_Doorbell_udp],ignore_index=True)\n",
    "gafgyt_attacks_Ennio_Doorbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Webcam_combo=pd.read_csv('gafgyt_attacks_Webcam/combo.csv', delimiter=',')\n",
    "gafgyt_attacks_Webcam_junk=pd.read_csv('gafgyt_attacks_Webcam/junk.csv', delimiter=',')\n",
    "gafgyt_attacks_Webcam_scan=pd.read_csv('gafgyt_attacks_Webcam/scan.csv', delimiter=',')\n",
    "gafgyt_attacks_Webcam_tcp=pd.read_csv('gafgyt_attacks_Webcam/tcp.csv', delimiter=',')\n",
    "gafgyt_attacks_Webcam_udp=pd.read_csv('gafgyt_attacks_Webcam/udp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafgyt_attacks_Webcam=pd.concat([gafgyt_attacks_Webcam_combo,gafgyt_attacks_Webcam_junk,gafgyt_attacks_Webcam_scan,gafgyt_attacks_Webcam_tcp,gafgyt_attacks_Webcam_udp],ignore_index=True)\n",
    "gafgyt_attacks_Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_1002_WHT_Security_Camera_ack=pd.read_csv('mirai_attacks_1002_WHT_Security_Camera/ack.csv', delimiter=',')\n",
    "mirai_attacks_1002_WHT_Security_Camera_scan=pd.read_csv('mirai_attacks_1002_WHT_Security_Camera/scan.csv', delimiter=',')\n",
    "mirai_attacks_1002_WHT_Security_Camera_syn=pd.read_csv('mirai_attacks_1002_WHT_Security_Camera/syn.csv', delimiter=',')\n",
    "mirai_attacks_1002_WHT_Security_Camera_udp=pd.read_csv('mirai_attacks_1002_WHT_Security_Camera/udp.csv', delimiter=',')\n",
    "mirai_attacks_1002_WHT_Security_Camera_udpplain=pd.read_csv('mirai_attacks_1002_WHT_Security_Camera/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_1002_WHT_Security_Camera=pd.concat([mirai_attacks_1002_WHT_Security_Camera_ack,mirai_attacks_1002_WHT_Security_Camera_scan,mirai_attacks_1002_WHT_Security_Camera_syn,mirai_attacks_1002_WHT_Security_Camera_udp,mirai_attacks_1002_WHT_Security_Camera_udpplain],ignore_index=True)\n",
    "mirai_attacks_1002_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_1003_WHT_Security_Camera_ack=pd.read_csv('mirai_attacks_1003_WHT_Security_Camera/ack.csv', delimiter=',')\n",
    "mirai_attacks_1003_WHT_Security_Camera_scan=pd.read_csv('mirai_attacks_1003_WHT_Security_Camera/scan.csv', delimiter=',')\n",
    "mirai_attacks_1003_WHT_Security_Camera_syn=pd.read_csv('mirai_attacks_1003_WHT_Security_Camera/syn.csv', delimiter=',')\n",
    "mirai_attacks_1003_WHT_Security_Camera_udp=pd.read_csv('mirai_attacks_1003_WHT_Security_Camera/udp.csv', delimiter=',')\n",
    "mirai_attacks_1003_WHT_Security_Camera_udpplain=pd.read_csv('mirai_attacks_1003_WHT_Security_Camera/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_1003_WHT_Security_Camera=pd.concat([mirai_attacks_1003_WHT_Security_Camera_ack,mirai_attacks_1003_WHT_Security_Camera_scan,mirai_attacks_1003_WHT_Security_Camera_syn,mirai_attacks_1003_WHT_Security_Camera_udp,mirai_attacks_1003_WHT_Security_Camera_udpplain],ignore_index=True)\n",
    "mirai_attacks_1003_WHT_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_737E_Security_Camera_ack=pd.read_csv('mirai_attacks_737E_Security_Camera/ack.csv', delimiter=',')\n",
    "mirai_attacks_737E_Security_Camera_scan=pd.read_csv('mirai_attacks_737E_Security_Camera/scan.csv', delimiter=',')\n",
    "mirai_attacks_737E_Security_Camera_syn=pd.read_csv('mirai_attacks_737E_Security_Camera/syn.csv', delimiter=',')\n",
    "mirai_attacks_737E_Security_Camera_udp=pd.read_csv('mirai_attacks_737E_Security_Camera/udp.csv', delimiter=',')\n",
    "mirai_attacks_737E_Security_Camera_udpplain=pd.read_csv('mirai_attacks_737E_Security_Camera/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_737E_Security_Camera=pd.concat([mirai_attacks_737E_Security_Camera_ack,mirai_attacks_737E_Security_Camera_scan,mirai_attacks_737E_Security_Camera_syn,mirai_attacks_737E_Security_Camera_udp,mirai_attacks_737E_Security_Camera_udpplain],ignore_index=True)\n",
    "mirai_attacks_737E_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_838_Security_Camera_ack=pd.read_csv('mirai_attacks_838_Security_Camera/ack.csv', delimiter=',')\n",
    "mirai_attacks_838_Security_Camera_scan=pd.read_csv('mirai_attacks_838_Security_Camera/scan.csv', delimiter=',')\n",
    "mirai_attacks_838_Security_Camera_syn=pd.read_csv('mirai_attacks_838_Security_Camera/syn.csv', delimiter=',')\n",
    "mirai_attacks_838_Security_Camera_udp=pd.read_csv('mirai_attacks_838_Security_Camera/udp.csv', delimiter=',')\n",
    "mirai_attacks_838_Security_Camera_udpplain=pd.read_csv('mirai_attacks_838_Security_Camera/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_838_Security_Camera=pd.concat([mirai_attacks_838_Security_Camera_ack,mirai_attacks_838_Security_Camera_scan,mirai_attacks_838_Security_Camera_syn,mirai_attacks_838_Security_Camera_udp,mirai_attacks_838_Security_Camera_udpplain],ignore_index=True)\n",
    "mirai_attacks_838_Security_Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Baby_Monitor_ack=pd.read_csv('mirai_attacks_Baby_Monitor/ack.csv', delimiter=',')\n",
    "mirai_attacks_Baby_Monitor_scan=pd.read_csv('mirai_attacks_Baby_Monitor/scan.csv', delimiter=',')\n",
    "mirai_attacks_Baby_Monitor_syn=pd.read_csv('mirai_attacks_Baby_Monitor/syn.csv', delimiter=',')\n",
    "mirai_attacks_Baby_Monitor_udp=pd.read_csv('mirai_attacks_Baby_Monitor/udp.csv', delimiter=',')\n",
    "mirai_attacks_Baby_Monitor_udpplain=pd.read_csv('mirai_attacks_Baby_Monitor/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Baby_Monitor=pd.concat([mirai_attacks_Baby_Monitor_ack,mirai_attacks_Baby_Monitor_scan,mirai_attacks_Baby_Monitor_syn,mirai_attacks_Baby_Monitor_udp,mirai_attacks_Baby_Monitor_udpplain],ignore_index=True)\n",
    "mirai_attacks_Baby_Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Danmini_Doorbell_ack=pd.read_csv('mirai_attacks_Danmini_Doorbell/ack.csv', delimiter=',')\n",
    "mirai_attacks_Danmini_Doorbell_scan=pd.read_csv('mirai_attacks_Danmini_Doorbell/scan.csv', delimiter=',')\n",
    "mirai_attacks_Danmini_Doorbell_syn=pd.read_csv('mirai_attacks_Danmini_Doorbell/syn.csv', delimiter=',')\n",
    "mirai_attacks_Danmini_Doorbell_udp=pd.read_csv('mirai_attacks_Danmini_Doorbell/udp.csv', delimiter=',')\n",
    "mirai_attacks_Danmini_Doorbell_udpplain=pd.read_csv('mirai_attacks_Danmini_Doorbell/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Danmini_Doorbell=pd.concat([mirai_attacks_Danmini_Doorbell_ack,mirai_attacks_Danmini_Doorbell_scan,mirai_attacks_Danmini_Doorbell_syn,mirai_attacks_Danmini_Doorbell_udp,mirai_attacks_Danmini_Doorbell_udpplain],ignore_index=True)\n",
    "mirai_attacks_Danmini_Doorbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Ecobee_Thermostat_ack=pd.read_csv('mirai_attacks_Ecobee_Thermostat/ack.csv', delimiter=',')\n",
    "mirai_attacks_Ecobee_Thermostat_scan=pd.read_csv('mirai_attacks_Ecobee_Thermostat/scan.csv', delimiter=',')\n",
    "mirai_attacks_Ecobee_Thermostat_syn=pd.read_csv('mirai_attacks_Ecobee_Thermostat/syn.csv', delimiter=',')\n",
    "mirai_attacks_Ecobee_Thermostat_udp=pd.read_csv('mirai_attacks_Ecobee_Thermostat/udp.csv', delimiter=',')\n",
    "mirai_attacks_Ecobee_Thermostat_udpplain=pd.read_csv('mirai_attacks_Ecobee_Thermostat/udpplain.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_attacks_Ecobee_Thermostat=pd.concat([mirai_attacks_Ecobee_Thermostat_ack,mirai_attacks_Ecobee_Thermostat_scan,mirai_attacks_Ecobee_Thermostat_syn,mirai_attacks_Ecobee_Thermostat_udp,mirai_attacks_Ecobee_Thermostat_udpplain],ignore_index=True)\n",
    "mirai_attacks_Ecobee_Thermostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_traffic=pd.concat([gafgyt_attacks_1002_WHT_Security_Camera,gafgyt_attacks_1003_WHT_Security_Camera,gafgyt_attacks_737E_Security_Camera,gafgyt_attacks_838_Security_Camera,gafgyt_attacks_Baby_Monitor,gafgyt_attacks_Danmini_Doorbell,gafgyt_attacks_Ecobee_Thermostat,gafgyt_attacks_Ennio_Doorbell,gafgyt_attacks_Webcam,mirai_attacks_1002_WHT_Security_Camera,mirai_attacks_1003_WHT_Security_Camera,mirai_attacks_737E_Security_Camera,mirai_attacks_838_Security_Camera,mirai_attacks_Baby_Monitor,mirai_attacks_Danmini_Doorbell,mirai_attacks_Ecobee_Thermostat],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_traffic['benign']=0\n",
    "malign_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETTURA DEL DATASET E CONCATENAZIONE DELLE TABELLE IN BENIGNE E MALEVOLE FINITA. CONVERSIONE DI TALI TABELLE IN NUMPY+ DIVISIONE TRA TRAINING E TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic = benign_traffic.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_traffic = malign_traffic.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic=benign_traffic.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_traffic_train, benign_traffic_test = train_test_split(benign_traffic, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_training_features = benign_traffic_train[:,0:-1]\n",
    "benign_training_labels = benign_traffic_train[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_testing_features = benign_traffic_test[:,0:-1]\n",
    "benign_testing_labels = benign_traffic_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_traffic=malign_traffic.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_traffic_features = malign_traffic[:,0:-1]\n",
    "malign_traffic_labels = malign_traffic[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_traffic= np.concatenate([malign_traffic,benign_traffic_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(testing_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_traffic_features = testing_traffic[:,0:-1]\n",
    "testing_traffic_labels = testing_traffic[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2=MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAZIONE DEI MODELLI DI AUTOENCODER(ENSAMBLE LAYER E OUTPUT LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble2 = Sequential()\n",
    "Ensemble2.add(Dense(units=23, activation='relu',input_shape=(23,)))\n",
    "Ensemble2.add(Dense(units=15, activation='relu'))\n",
    "Ensemble2.add(Dense(units=23, activation='sigmoid'))\n",
    "Ensemble2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble3 = Sequential()\n",
    "Ensemble3.add(Dense(units=23, activation='relu',input_shape=(23,)))\n",
    "Ensemble3.add(Dense(units=15, activation='relu'))\n",
    "Ensemble3.add(Dense(units=23, activation='sigmoid'))\n",
    "Ensemble3.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble4= Sequential()\n",
    "Ensemble4.add(Dense(units=23, activation='relu',input_shape=(23,)))\n",
    "Ensemble4.add(Dense(units=15, activation='relu'))\n",
    "Ensemble4.add(Dense(units=23, activation='sigmoid'))\n",
    "Ensemble4.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble5 = Sequential()\n",
    "Ensemble5.add(Dense(units=23, activation='relu',input_shape=(23,)))\n",
    "Ensemble5.add(Dense(units=15, activation='relu'))\n",
    "Ensemble5.add(Dense(units=23, activation='sigmoid'))\n",
    "Ensemble5.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble1 = Sequential()\n",
    "Ensemble1.add(Dense(units=23,activation='relu', input_shape=(23,)))\n",
    "Ensemble1.add(Dense(units=15, activation='relu'))\n",
    "Ensemble1.add(Dense(units=23, activation='sigmoid'))\n",
    "Ensemble1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Sequential()\n",
    "Output.add(Dense(units=5, activation='relu',input_shape=(5,)))\n",
    "Output.add(Dense(units=3, activation='relu'))\n",
    "Output.add(Dense(units=5, activation='sigmoid'))\n",
    "Output.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAZIONE SCALER PER NORMALIZZAZIONE 0-1 DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1=MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZZAZIONE CON FIT DEI DATI DI TRAINING\n",
    "benign_training_features=scaler1.fit_transform(benign_training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZZAZIONE DEI DATI DI TESTING\n",
    "testing_traffic_features=scaler1.transform(testing_traffic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVISIONE DELLE FEATURES PER I VARI AUTOENCODER(23 FEATURES PER 5 AUTOENCODER NELL'ENSEMBLE LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_training_features1=benign_training_features[:,:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_training_features2=benign_training_features[:,23:46]\n",
    "benign_training_features3=benign_training_features[:,46:69]\n",
    "benign_training_features4=benign_training_features[:,69:92]\n",
    "benign_training_features5=benign_training_features[:,92:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=np.zeros((benign_training_features.shape[0],5))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 746us/step - loss: 0.0021 - accuracy: 0.75780s - loss: 0.0021 - accura\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 738us/step - loss: 3.9034e-05 - accuracy: 0.7983\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 9s 746us/step - loss: 3.0512e-05 - accuracy: 0.8155\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 742us/step - loss: 2.5541e-05 - accuracy: 0.82580s - loss: 2.5650e-0\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 9s 779us/step - loss: 2.2419e-05 - accuracy: 0.8279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2702a514288>"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT DEL PRIMO AUTOENCODER\n",
    "Ensemble1.fit(benign_training_features1,benign_training_features1,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIZIONE DEL PRIMO AUTOENCODER + INSERIMENTO DELL'RMSE TRA PREDIZIONE E DATI REALI PER OGNI RIGA DI TRAFFICO ALL'INTERNO DELLA MATRICE SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble1.predict(benign_training_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=np.zeros((benign_training_features1.shape[0],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score[i,0]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features1[i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12161/12161 [==============================] - 10s 798us/step - loss: 1.0327e-04 - accuracy: 0.9739\n",
      "Epoch 2/10\n",
      "12161/12161 [==============================] - 10s 811us/step - loss: 7.2441e-05 - accuracy: 0.9750\n",
      "Epoch 3/10\n",
      "12161/12161 [==============================] - 10s 835us/step - loss: 6.0944e-05 - accuracy: 0.9754\n",
      "Epoch 4/10\n",
      "12161/12161 [==============================] - 10s 837us/step - loss: 5.4890e-05 - accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "12161/12161 [==============================] - 10s 850us/step - loss: 5.0698e-05 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "12161/12161 [==============================] - 10s 844us/step - loss: 4.8042e-05 - accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "12161/12161 [==============================] - 10s 843us/step - loss: 4.5655e-05 - accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "12161/12161 [==============================] - 10s 846us/step - loss: 4.3648e-05 - accuracy: 0.9758\n",
      "Epoch 9/10\n",
      "12161/12161 [==============================] - 10s 858us/step - loss: 4.2131e-05 - accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "12161/12161 [==============================] - 10s 863us/step - loss: 4.0649e-05 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2702544f248>"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FIT SECONDO AUTOENCODER + PASSAGGI DI PRIMA (VALE PER TUTTI E 5 GLI AUTOENCODER)\n",
    "Ensemble2.fit(benign_training_features2,benign_training_features2,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble2.predict(benign_training_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score[i,1]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    1/12161 [..............................] - ETA: 0s - loss: 0.1672 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "12161/12161 [==============================] - 10s 830us/step - loss: 0.0021 - accuracy: 0.8908s - loss: 0.0021 - accuracy: 0.\n",
      "Epoch 2/10\n",
      "12161/12161 [==============================] - 10s 830us/step - loss: 1.7420e-04 - accuracy: 0.9456\n",
      "Epoch 3/10\n",
      "12161/12161 [==============================] - 10s 851us/step - loss: 1.1841e-04 - accuracy: 0.9651\n",
      "Epoch 4/10\n",
      "12161/12161 [==============================] - 10s 850us/step - loss: 9.7838e-05 - accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "12161/12161 [==============================] - 10s 857us/step - loss: 8.3136e-05 - accuracy: 0.9794\n",
      "Epoch 6/10\n",
      "12161/12161 [==============================] - 10s 859us/step - loss: 7.5657e-05 - accuracy: 0.9810\n",
      "Epoch 7/10\n",
      "12161/12161 [==============================] - 10s 853us/step - loss: 7.1741e-05 - accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "12161/12161 [==============================] - 10s 863us/step - loss: 6.8999e-05 - accuracy: 0.9811\n",
      "Epoch 9/10\n",
      "12161/12161 [==============================] - 11s 867us/step - loss: 6.6730e-05 - accuracy: 0.9810\n",
      "Epoch 10/10\n",
      "12161/12161 [==============================] - 10s 854us/step - loss: 6.2116e-05 - accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2702c70ef48>"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble3.fit(benign_training_features3,benign_training_features3,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble3.predict(benign_training_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score[i,2]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12161/12161 [==============================] - 10s 824us/step - loss: 4.0085e-05 - accuracy: 0.9878\n",
      "Epoch 2/10\n",
      "12161/12161 [==============================] - 10s 854us/step - loss: 2.7939e-05 - accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "12161/12161 [==============================] - 11s 895us/step - loss: 2.3232e-05 - accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "12161/12161 [==============================] - 11s 891us/step - loss: 1.9752e-05 - accuracy: 0.9891\n",
      "Epoch 5/10\n",
      "12161/12161 [==============================] - 11s 882us/step - loss: 1.7411e-05 - accuracy: 0.9891\n",
      "Epoch 6/10\n",
      "12161/12161 [==============================] - 11s 894us/step - loss: 1.5970e-05 - accuracy: 0.9893\n",
      "Epoch 7/10\n",
      "12161/12161 [==============================] - 11s 873us/step - loss: 1.5008e-05 - accuracy: 0.9901\n",
      "Epoch 8/10\n",
      "12161/12161 [==============================] - 11s 864us/step - loss: 1.4067e-05 - accuracy: 0.9906\n",
      "Epoch 9/10\n",
      "12161/12161 [==============================] - 10s 856us/step - loss: 1.3118e-05 - accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "12161/12161 [==============================] - 10s 856us/step - loss: 1.2626e-05 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26e819ca908>"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble4.fit(benign_training_features4,benign_training_features4,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble4.predict(benign_training_features4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score[i,3]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12161/12161 [==============================] - 10s 826us/step - loss: 0.0013 - accuracy: 0.9770\n",
      "Epoch 2/10\n",
      "12161/12161 [==============================] - 11s 902us/step - loss: 8.4150e-05 - accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "12161/12161 [==============================] - 11s 909us/step - loss: 6.0230e-05 - accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "12161/12161 [==============================] - 11s 891us/step - loss: 5.1543e-05 - accuracy: 0.9923\n",
      "Epoch 5/10\n",
      "12161/12161 [==============================] - 11s 882us/step - loss: 4.7152e-05 - accuracy: 0.9930\n",
      "Epoch 6/10\n",
      "12161/12161 [==============================] - 11s 882us/step - loss: 4.4068e-05 - accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "12161/12161 [==============================] - 11s 870us/step - loss: 4.1742e-05 - accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "12161/12161 [==============================] - 11s 865us/step - loss: 3.9310e-05 - accuracy: 0.9944\n",
      "Epoch 9/10\n",
      "12161/12161 [==============================] - 11s 866us/step - loss: 3.7279e-05 - accuracy: 0.9947\n",
      "Epoch 10/10\n",
      "12161/12161 [==============================] - 11s 869us/step - loss: 3.4875e-05 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x270278e9588>"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble5.fit(benign_training_features5,benign_training_features5,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble5.predict(benign_training_features5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score[i,4]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSTRUITA LA MATRICE SCORE DEGLI RMSE DELL'ENSEMBLE LAYER, NORMALIZZO TALE MATRICE NEL RANGE 0-1 PER DARLO IN INPUT ALL'OUTPUT LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_transform=scaler2.fit_transform(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12161/12161 [==============================] - 9s 704us/step - loss: 8.0254e-05 - accuracy: 0.7806\n",
      "Epoch 2/10\n",
      "12161/12161 [==============================] - 9s 712us/step - loss: 8.0270e-05 - accuracy: 0.7845\n",
      "Epoch 3/10\n",
      "12161/12161 [==============================] - 9s 756us/step - loss: 8.0280e-05 - accuracy: 0.7798\n",
      "Epoch 4/10\n",
      "12161/12161 [==============================] - 9s 741us/step - loss: 8.0225e-05 - accuracy: 0.7793\n",
      "Epoch 5/10\n",
      "12161/12161 [==============================] - 9s 754us/step - loss: 8.0186e-05 - accuracy: 0.7816\n",
      "Epoch 6/10\n",
      "12161/12161 [==============================] - 9s 742us/step - loss: 8.0150e-05 - accuracy: 0.7815\n",
      "Epoch 7/10\n",
      "12161/12161 [==============================] - 9s 768us/step - loss: 8.0211e-05 - accuracy: 0.7832\n",
      "Epoch 8/10\n",
      "12161/12161 [==============================] - 10s 781us/step - loss: 8.0226e-05 - accuracy: 0.7807\n",
      "Epoch 9/10\n",
      "12161/12161 [==============================] - 9s 775us/step - loss: 8.0187e-05 - accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "12161/12161 [==============================] - 10s 804us/step - loss: 8.0162e-05 - accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26e81e2c4c8>"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADDESTRAMENTO OUTPUT LAYER DANDO IN INPUT GLI RMSE NORMALIZZATI DEGLI ENSEMBLE LAYER\n",
    "Output.fit(score_transform,score_transform,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIZIONE OUTPUT LAYER + COSTRUZIONE DEL VETTORE RMSE FINALE PER OGNI RIGA DI TRAFFICO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Output.predict(score_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE=np.zeros(score_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(score_transform.shape[0]):\n",
    "        RMSE[i]= np.sqrt(metrics.mean_squared_error(pred[i],score_transform[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOGLIA (VALUTATA COME MAX DEGLI RMSE FINALI DELL'OUTPUT LAYER) AL DI SOPRA DEL QUALE VALUTARE IN FASE DI TESTING TRAFFICO MALEVOLO RISPETTO A QUELLO BENIGNO\n",
    "Soglia= np.max(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37106783303192575"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soglia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINITA LA FASE DI TRAINING PASSIAMO A QUELLA DI ESECUZIONE. DIVIDIAMO IL DATASET DI TESTING IN 5 SOTTOINSIEMI DI FEATURES PER DARLO IN PASTO AI 5 AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_traffic_features1=testing_traffic_features[:,:23]\n",
    "testing_traffic_features2=testing_traffic_features[:,23:46]\n",
    "testing_traffic_features3=testing_traffic_features[:,46:69]\n",
    "testing_traffic_features4=testing_traffic_features[:,69:92]\n",
    "testing_traffic_features5=testing_traffic_features[:,92:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIZIONE DELLE PRIME 23 FEATURES PER RIGA DEL PRIMO AUTOENCODER E CALCOLO DELL'RMSE RELATIVO DA INSERIRE ALL'INTERNO DELLA MATRICE TESTING_SCORE\n",
    "# LO FACCIAMO PER TUTTI GLI AUTOENCODER RISPETTANDO I RELATIVI INPUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble1.predict(testing_traffic_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_score=np.zeros((testing_traffic_features.shape[0],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score[i,0]= np.sqrt(metrics.mean_squared_error(pred[i],testing_traffic_features1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble2.predict(testing_traffic_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score[i,1]= np.sqrt(metrics.mean_squared_error(pred[i],testing_traffic_features2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble3.predict(testing_traffic_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score[i,2]= np.sqrt(metrics.mean_squared_error(pred[i],testing_traffic_features3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble4.predict(testing_traffic_features4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score[i,3]= np.sqrt(metrics.mean_squared_error(pred[i],testing_traffic_features4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble5.predict(testing_traffic_features5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score[i,4]= np.sqrt(metrics.mean_squared_error(pred[i],testing_traffic_features5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZZAZIONE 0-1 DEGLI RMSE CALCOLATI DAI 5 AUTOENCODER DELL'ENSEMBLE LAYER (NORMALIZZIAMO RISPETTO ALLO SCALER2, OVVERO QUELLO CHE ABBIAMO ADDESTRANDO IN TRAINING)\n",
    "testing_score_transform=scaler2.transform(testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIZIONE DEGLI RMSE DELL'OUTPUT LAYER + CALCOLO DEGLI RMSE FINALI CALCOLATA SULLA PREDIZIONE E SUI DATI REALI + INSERIMENTO DEI VALORI NEL VETTORE FINAL_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Output.predict(testing_score_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_RMSE=np.zeros(testing_score_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score_transform.shape[0]):\n",
    "        Final_RMSE[i]= np.sqrt(metrics.mean_squared_error(pred[i],testing_score_transform[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVUTO GLI RMSE FINALI NELLA FASE DI ESECUZIONE MI SONO PREOCCUPATO DI TRADURRE I VALORI NELLE LABEL 0(MALEVOLO) o 1(BENIGNO) IN BASE A SE QUESTI \n",
    "# FOSSERO AL DI SOPRA DELLA SOGLIA O AL DI SOTTO DI ESSA. INFINE HO SEMPLICEMENTE CALCOLATO QUANTI FOSSERO GLI 0 e QUANTI GLI 1 (PER AVERE UN'IDEA DEL RISULTATO FINALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_labels=np.zeros(testing_score_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score_transform.shape[0]):\n",
    "        if Final_RMSE[i]<=Soglia:\n",
    "            Final_labels[i]=1\n",
    "        else:\n",
    "            Final_labels[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score_transform.shape[0]):\n",
    "        if Final_labels[i]==0:\n",
    "            a=a+1\n",
    "        else:\n",
    "            b=b+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691049"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1982405"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUOVO TENTATIVO CON GLI STESSI PROCEDIMENTI DI SOPRA MA CON 9 AUTOENCODER NELL'ENSEMBLE LAYER PER PROVARE AD OTTENERE VALORI MIGLIORI TRAMITE ACCURACY MIGLIORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASE DI CREAZIONE + TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_1 = Sequential()\n",
    "Ensemble_1.add(Dense(units=40,activation='relu', input_shape=(40,)))\n",
    "Ensemble_1.add(Dense(units=30, activation='relu'))\n",
    "Ensemble_1.add(Dense(units=40, activation='sigmoid'))\n",
    "Ensemble_1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_2 = Sequential()\n",
    "Ensemble_2.add(Dense(units=10,activation='relu', input_shape=(10,)))\n",
    "Ensemble_2.add(Dense(units=7, activation='relu'))\n",
    "Ensemble_2.add(Dense(units=10, activation='sigmoid'))\n",
    "Ensemble_2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_3 = Sequential()\n",
    "Ensemble_3.add(Dense(units=15,activation='relu', input_shape=(15,)))\n",
    "Ensemble_3.add(Dense(units=10, activation='relu'))\n",
    "Ensemble_3.add(Dense(units=15, activation='sigmoid'))\n",
    "Ensemble_3.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_4 = Sequential()\n",
    "Ensemble_4.add(Dense(units=15,activation='relu', input_shape=(15,)))\n",
    "Ensemble_4.add(Dense(units=10, activation='relu'))\n",
    "Ensemble_4.add(Dense(units=15, activation='sigmoid'))\n",
    "Ensemble_4.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_5 = Sequential()\n",
    "Ensemble_5.add(Dense(units=10,activation='relu', input_shape=(10,)))\n",
    "Ensemble_5.add(Dense(units=7, activation='relu'))\n",
    "Ensemble_5.add(Dense(units=10, activation='sigmoid'))\n",
    "Ensemble_5.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_6 = Sequential()\n",
    "Ensemble_6.add(Dense(units=10,activation='relu', input_shape=(10,)))\n",
    "Ensemble_6.add(Dense(units=7, activation='relu'))\n",
    "Ensemble_6.add(Dense(units=10, activation='sigmoid'))\n",
    "Ensemble_6.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_7 = Sequential()\n",
    "Ensemble_7.add(Dense(units=5,activation='relu', input_shape=(5,)))\n",
    "Ensemble_7.add(Dense(units=3, activation='relu'))\n",
    "Ensemble_7.add(Dense(units=5, activation='sigmoid'))\n",
    "Ensemble_7.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_8 = Sequential()\n",
    "Ensemble_8.add(Dense(units=5,activation='relu', input_shape=(5,)))\n",
    "Ensemble_8.add(Dense(units=3, activation='relu'))\n",
    "Ensemble_8.add(Dense(units=5, activation='sigmoid'))\n",
    "Ensemble_8.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_9 = Sequential()\n",
    "Ensemble_9.add(Dense(units=5,activation='relu', input_shape=(5,)))\n",
    "Ensemble_9.add(Dense(units=3, activation='relu'))\n",
    "Ensemble_9.add(Dense(units=5, activation='sigmoid'))\n",
    "Ensemble_9.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_ = Sequential()\n",
    "Output_.add(Dense(units=9,activation='relu', input_shape=(9,)))\n",
    "Output_.add(Dense(units=7, activation='relu'))\n",
    "Output_.add(Dense(units=9, activation='sigmoid'))\n",
    "Output_.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_training_features_1=benign_training_features[:,:40]\n",
    "benign_training_features_2=benign_training_features[:,40:50]\n",
    "benign_training_features_3=benign_training_features[:,50:65]\n",
    "benign_training_features_4=benign_training_features[:,65:80]\n",
    "benign_training_features_5=benign_training_features[:,80:90]\n",
    "benign_training_features_6=benign_training_features[:,90:100]\n",
    "benign_training_features_7=benign_training_features[:,100:105]\n",
    "benign_training_features_8=benign_training_features[:,105:110]\n",
    "benign_training_features_9=benign_training_features[:,110:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 10s 837us/step - loss: 2.1248e-05 - accuracy: 0.9875\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 10s 855us/step - loss: 1.9816e-05 - accuracy: 0.9876\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 10s 845us/step - loss: 1.8295e-05 - accuracy: 0.9877\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 10s 840us/step - loss: 1.7168e-05 - accuracy: 0.9889\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 10s 836us/step - loss: 1.6004e-05 - accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2705aabfd08>"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_1.fit(benign_training_features_1,benign_training_features_1,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 747us/step - loss: 0.0023 - accuracy: 0.8962\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 745us/step - loss: 1.2660e-04 - accuracy: 0.9636\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 9s 744us/step - loss: 9.9611e-05 - accuracy: 0.9723\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 760us/step - loss: 7.6609e-05 - accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 9s 768us/step - loss: 6.5608e-05 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2705bbb9488>"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_2.fit(benign_training_features_2,benign_training_features_2,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 769us/step - loss: 0.0023 - accuracy: 0.8885\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 772us/step - loss: 1.9900e-04 - accuracy: 0.9456\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 9s 772us/step - loss: 1.3795e-04 - accuracy: 0.9578\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 10s 784us/step - loss: 1.1493e-04 - accuracy: 0.9627\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 10s 787us/step - loss: 9.6666e-05 - accuracy: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2705cfa5b88>"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_3.fit(benign_training_features_3,benign_training_features_3,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 754us/step - loss: 0.0028 - accuracy: 0.90380s - loss: 0.0029 - \n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 767us/step - loss: 1.4542e-05 - accuracy: 0.9627\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 10s 791us/step - loss: 9.2662e-06 - accuracy: 0.9701\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 779us/step - loss: 7.3213e-06 - accuracy: 0.9746\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 9s 776us/step - loss: 6.5354e-06 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2705d0dad08>"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_4.fit(benign_training_features_4,benign_training_features_4,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 734us/step - loss: 0.0029 - accuracy: 0.9837\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 753us/step - loss: 9.2435e-05 - accuracy: 0.9907\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 10s 783us/step - loss: 6.0150e-05 - accuracy: 0.9913\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 757us/step - loss: 5.7363e-05 - accuracy: 0.9913\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 10s 787us/step - loss: 5.5559e-05 - accuracy: 0.9913s - loss: 5.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27061f12e88>"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_5.fit(benign_training_features_5,benign_training_features_5,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 9s 745us/step - loss: 0.0021 - accuracy: 0.9541\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 10s 786us/step - loss: 8.8915e-05 - accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 9s 752us/step - loss: 7.0863e-05 - accuracy: 0.9920\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 773us/step - loss: 6.5705e-05 - accuracy: 0.9934\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 9s 768us/step - loss: 6.3178e-05 - accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2706201d5c8>"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_6.fit(benign_training_features_6,benign_training_features_6,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 8s 667us/step - loss: 0.0044 - accuracy: 0.9579\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 8s 669us/step - loss: 5.5999e-04 - accuracy: 0.9794\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 8s 666us/step - loss: 5.0582e-04 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 8s 671us/step - loss: 4.9225e-04 - accuracy: 0.9792\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 8s 684us/step - loss: 4.5660e-04 - accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27066191a08>"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_7.fit(benign_training_features_7,benign_training_features_7,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 8s 673us/step - loss: 7.1695e-04 - accuracy: 0.9905\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 8s 670us/step - loss: 7.1323e-04 - accuracy: 0.9906\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 8s 677us/step - loss: 7.1047e-04 - accuracy: 0.9906\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 8s 678us/step - loss: 7.0827e-04 - accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 8s 680us/step - loss: 7.0116e-04 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x270662ad608>"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_8.fit(benign_training_features_8,benign_training_features_8,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12161/12161 [==============================] - 8s 685us/step - loss: 5.4752e-04 - accuracy: 0.9876\n",
      "Epoch 2/5\n",
      "12161/12161 [==============================] - 9s 701us/step - loss: 5.3817e-04 - accuracy: 0.9880\n",
      "Epoch 3/5\n",
      "12161/12161 [==============================] - 9s 716us/step - loss: 5.2756e-04 - accuracy: 0.9879\n",
      "Epoch 4/5\n",
      "12161/12161 [==============================] - 9s 727us/step - loss: 5.1883e-04 - accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "12161/12161 [==============================] - 9s 700us/step - loss: 5.1600e-04 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2703ba7b508>"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_9.fit(benign_training_features_9,benign_training_features_9,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1=np.zeros((benign_training_features.shape[0],9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_1.predict(benign_training_features_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,0]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_2.predict(benign_training_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,1]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_3.predict(benign_training_features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,2]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_4.predict(benign_training_features_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,3]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_5.predict(benign_training_features_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,4]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_6.predict(benign_training_features_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,5]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_7.predict(benign_training_features_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,6]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_7[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_8.predict(benign_training_features_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,7]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_9.predict(benign_training_features_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(benign_training_features.shape[0]):\n",
    "        score1[i,8]= np.sqrt(metrics.mean_squared_error(pred[i],benign_training_features_9[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler3=MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1_transform=scaler3.fit_transform(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12161/12161 [==============================] - 9s 739us/step - loss: 9.2996e-05 - accuracy: 0.8126\n",
      "Epoch 2/50\n",
      "12161/12161 [==============================] - 9s 735us/step - loss: 9.2794e-05 - accuracy: 0.8124\n",
      "Epoch 3/50\n",
      "12161/12161 [==============================] - 9s 733us/step - loss: 9.2623e-05 - accuracy: 0.8127\n",
      "Epoch 4/50\n",
      "12161/12161 [==============================] - 9s 732us/step - loss: 9.2524e-05 - accuracy: 0.8128\n",
      "Epoch 5/50\n",
      "12161/12161 [==============================] - 9s 730us/step - loss: 9.2381e-05 - accuracy: 0.8130\n",
      "Epoch 6/50\n",
      "12161/12161 [==============================] - 9s 751us/step - loss: 9.2366e-05 - accuracy: 0.8131\n",
      "Epoch 7/50\n",
      "12161/12161 [==============================] - 9s 751us/step - loss: 9.2279e-05 - accuracy: 0.8132\n",
      "Epoch 8/50\n",
      "12161/12161 [==============================] - 9s 753us/step - loss: 9.2296e-05 - accuracy: 0.8129\n",
      "Epoch 9/50\n",
      "12161/12161 [==============================] - 9s 760us/step - loss: 9.2213e-05 - accuracy: 0.8134\n",
      "Epoch 10/50\n",
      "12161/12161 [==============================] - 9s 775us/step - loss: 9.2155e-05 - accuracy: 0.8129\n",
      "Epoch 11/50\n",
      "12161/12161 [==============================] - 8s 651us/step - loss: 9.2140e-05 - accuracy: 0.8129\n",
      "Epoch 12/50\n",
      "12161/12161 [==============================] - 8s 649us/step - loss: 9.2133e-05 - accuracy: 0.8134\n",
      "Epoch 13/50\n",
      "12161/12161 [==============================] - 8s 645us/step - loss: 9.2158e-05 - accuracy: 0.8131\n",
      "Epoch 14/50\n",
      "12161/12161 [==============================] - 7s 613us/step - loss: 9.2117e-05 - accuracy: 0.8133\n",
      "Epoch 15/50\n",
      "12161/12161 [==============================] - 7s 609us/step - loss: 9.2055e-05 - accuracy: 0.8131\n",
      "Epoch 16/50\n",
      "12161/12161 [==============================] - 7s 611us/step - loss: 9.2144e-05 - accuracy: 0.8131\n",
      "Epoch 17/50\n",
      "12161/12161 [==============================] - 7s 609us/step - loss: 9.2092e-05 - accuracy: 0.8127\n",
      "Epoch 18/50\n",
      "12161/12161 [==============================] - 7s 612us/step - loss: 9.2070e-05 - accuracy: 0.8130\n",
      "Epoch 19/50\n",
      "12161/12161 [==============================] - 7s 615us/step - loss: 9.2092e-05 - accuracy: 0.8131\n",
      "Epoch 20/50\n",
      "12161/12161 [==============================] - 7s 610us/step - loss: 9.2056e-05 - accuracy: 0.8130\n",
      "Epoch 21/50\n",
      "12161/12161 [==============================] - 7s 615us/step - loss: 9.2059e-05 - accuracy: 0.8134\n",
      "Epoch 22/50\n",
      "12161/12161 [==============================] - 8s 644us/step - loss: 9.2078e-05 - accuracy: 0.8135\n",
      "Epoch 23/50\n",
      "12161/12161 [==============================] - 8s 676us/step - loss: 9.2040e-05 - accuracy: 0.8130\n",
      "Epoch 24/50\n",
      "12161/12161 [==============================] - 8s 693us/step - loss: 9.1988e-05 - accuracy: 0.8138\n",
      "Epoch 25/50\n",
      "12161/12161 [==============================] - 8s 697us/step - loss: 9.2044e-05 - accuracy: 0.8133\n",
      "Epoch 26/50\n",
      "12161/12161 [==============================] - 8s 671us/step - loss: 9.1972e-05 - accuracy: 0.8137\n",
      "Epoch 27/50\n",
      "12161/12161 [==============================] - 8s 686us/step - loss: 9.1965e-05 - accuracy: 0.8136\n",
      "Epoch 28/50\n",
      "12161/12161 [==============================] - 8s 656us/step - loss: 9.1932e-05 - accuracy: 0.8139\n",
      "Epoch 29/50\n",
      "12161/12161 [==============================] - 8s 633us/step - loss: 9.1910e-05 - accuracy: 0.8138\n",
      "Epoch 30/50\n",
      "12161/12161 [==============================] - 8s 623us/step - loss: 9.1898e-05 - accuracy: 0.8139\n",
      "Epoch 31/50\n",
      "12161/12161 [==============================] - 8s 628us/step - loss: 9.1974e-05 - accuracy: 0.8140\n",
      "Epoch 32/50\n",
      "12161/12161 [==============================] - 8s 678us/step - loss: 9.1937e-05 - accuracy: 0.8139\n",
      "Epoch 33/50\n",
      "12161/12161 [==============================] - 8s 657us/step - loss: 9.1939e-05 - accuracy: 0.8140\n",
      "Epoch 34/50\n",
      "12161/12161 [==============================] - 8s 655us/step - loss: 9.1906e-05 - accuracy: 0.8141\n",
      "Epoch 35/50\n",
      "12161/12161 [==============================] - 8s 623us/step - loss: 9.1921e-05 - accuracy: 0.8138\n",
      "Epoch 36/50\n",
      "12161/12161 [==============================] - 8s 664us/step - loss: 9.1876e-05 - accuracy: 0.8137\n",
      "Epoch 37/50\n",
      "12161/12161 [==============================] - 8s 649us/step - loss: 9.1846e-05 - accuracy: 0.8139\n",
      "Epoch 38/50\n",
      "12161/12161 [==============================] - ETA: 0s - loss: 9.1775e-05 - accuracy: 0.81 - 8s 648us/step - loss: 9.1779e-05 - accuracy: 0.8139\n",
      "Epoch 39/50\n",
      "12161/12161 [==============================] - 8s 656us/step - loss: 9.1819e-05 - accuracy: 0.81430s - loss: 9.1855e-05 \n",
      "Epoch 40/50\n",
      "12161/12161 [==============================] - 8s 658us/step - loss: 9.1777e-05 - accuracy: 0.8142\n",
      "Epoch 41/50\n",
      "12161/12161 [==============================] - 8s 661us/step - loss: 9.1667e-05 - accuracy: 0.8142\n",
      "Epoch 42/50\n",
      "12161/12161 [==============================] - 8s 678us/step - loss: 9.1743e-05 - accuracy: 0.81430s - loss:\n",
      "Epoch 43/50\n",
      "12161/12161 [==============================] - 8s 643us/step - loss: 9.1729e-05 - accuracy: 0.8143\n",
      "Epoch 44/50\n",
      "12161/12161 [==============================] - 8s 679us/step - loss: 9.1682e-05 - accuracy: 0.8145\n",
      "Epoch 45/50\n",
      "12161/12161 [==============================] - 8s 655us/step - loss: 9.1697e-05 - accuracy: 0.8144\n",
      "Epoch 46/50\n",
      "12161/12161 [==============================] - 9s 702us/step - loss: 9.1673e-05 - accuracy: 0.8144\n",
      "Epoch 47/50\n",
      "12161/12161 [==============================] - 8s 621us/step - loss: 9.1705e-05 - accuracy: 0.8142\n",
      "Epoch 48/50\n",
      "12161/12161 [==============================] - 8s 623us/step - loss: 9.1753e-05 - accuracy: 0.8144\n",
      "Epoch 49/50\n",
      "12161/12161 [==============================] - 8s 629us/step - loss: 9.1714e-05 - accuracy: 0.8144\n",
      "Epoch 50/50\n",
      "12161/12161 [==============================] - 8s 625us/step - loss: 9.1723e-05 - accuracy: 0.8145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2705bab5208>"
      ]
     },
     "execution_count": 1039,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output_.fit(score1_transform,score1_transform,epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing1=testing_traffic_features[:,:40]\n",
    "testing2=testing_traffic_features[:,40:50]\n",
    "testing3=testing_traffic_features[:,50:65]\n",
    "testing4=testing_traffic_features[:,65:80]\n",
    "testing5=testing_traffic_features[:,80:90]\n",
    "testing6=testing_traffic_features[:,90:100]\n",
    "testing7=testing_traffic_features[:,100:105]\n",
    "testing8=testing_traffic_features[:,105:110]\n",
    "testing9=testing_traffic_features[:,110:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_score1=np.zeros((testing_traffic_features.shape[0],9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Output_.predict(score1_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1=np.zeros(score1_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(score1_transform.shape[0]):\n",
    "        RMSE1[i]= np.sqrt(metrics.mean_squared_error(pred[i],score1_transform[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "Soglia= np.max(RMSE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22757923522803356"
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soglia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINE FASE TRAINING INIZIO FASE ESECUZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_1.predict(testing1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,0]= np.sqrt(metrics.mean_squared_error(pred[i],testing1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_2.predict(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,1]= np.sqrt(metrics.mean_squared_error(pred[i],testing2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_3.predict(testing3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,2]= np.sqrt(metrics.mean_squared_error(pred[i],testing3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_4.predict(testing4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,3]= np.sqrt(metrics.mean_squared_error(pred[i],testing4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_5.predict(testing5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,4]= np.sqrt(metrics.mean_squared_error(pred[i],testing5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_6.predict(testing6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,5]= np.sqrt(metrics.mean_squared_error(pred[i],testing6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_7.predict(testing7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,6]= np.sqrt(metrics.mean_squared_error(pred[i],testing7[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_8.predict(testing8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,7]= np.sqrt(metrics.mean_squared_error(pred[i],testing8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ensemble_9.predict(testing9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_traffic_features.shape[0]):\n",
    "        testing_score1[i,8]= np.sqrt(metrics.mean_squared_error(pred[i],testing9[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_score1_transform=scaler3.transform(testing_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Output_.predict(testing_score1_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_RMSE1=np.zeros(testing_score1_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score1_transform.shape[0]):\n",
    "        Final_RMSE1[i]= np.sqrt(metrics.mean_squared_error(pred[i],testing_score1_transform[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_labels1=np.zeros(testing_score1_transform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score1_transform.shape[0]):\n",
    "        if Final_RMSE1[i]<=Soglia:\n",
    "            Final_labels1[i]=1\n",
    "        else:\n",
    "            Final_labels1[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(testing_score1_transform.shape[0]):\n",
    "        if Final_labels1[i]==0:\n",
    "            a=a+1\n",
    "        else:\n",
    "            b=b+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4693287"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980167"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
